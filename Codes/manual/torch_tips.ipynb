{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## torch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `broadcast`\n",
    "- Docs about this feature is concise\n",
    "- cannot handle dimension size larger than 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.1536, 0.5777, 0.1836, 0.1555, 0.0351],\n",
       "         [0.0210, 0.0448, 0.2552, 0.3459, 0.1751],\n",
       "         [0.0208, 0.0027, 0.4269, 0.2744, 0.3023],\n",
       "         [0.2878, 0.5131, 0.2553, 0.6664, 0.1479],\n",
       "         [0.8311, 0.2688, 0.7493, 0.1318, 0.0262],\n",
       "         [0.6754, 0.0981, 0.1209, 0.8408, 0.2742]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[[0.7299, 0.6202, 0.6148]]]),\n",
       " tensor([[1.1536, 1.5777, 1.1836, 1.1555, 1.0351],\n",
       "         [1.0210, 1.0448, 1.2552, 1.3459, 1.1751],\n",
       "         [1.0208, 1.0027, 1.4269, 1.2744, 1.3023],\n",
       "         [1.2878, 1.5131, 1.2553, 1.6664, 1.1479],\n",
       "         [1.8311, 1.2688, 1.7493, 1.1318, 1.0262],\n",
       "         [1.6754, 1.0981, 1.1209, 1.8408, 1.2742]]),\n",
       " tensor([[[1.7299, 1.6202, 1.6148],\n",
       "          [1.7299, 1.6202, 1.6148],\n",
       "          [1.7299, 1.6202, 1.6148],\n",
       "          [1.7299, 1.6202, 1.6148],\n",
       "          [1.7299, 1.6202, 1.6148],\n",
       "          [1.7299, 1.6202, 1.6148]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand((6,5))\n",
    "b = torch.ones((6,1))\n",
    "c = torch.rand((1,1,3))\n",
    "\n",
    "a,b,c,a+b,b+c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `repeat_interleave`\n",
    "repeating samples along axis\n",
    "\n",
    "- equal to *cat and view*\n",
    "- *broadcast* a tensor when the dimension is not 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[1, 2]],\n\n        [[2, 3]]]) torch.Size([2, 1, 2])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]),\n",
       " tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.tensor([[[1,2]],[[2,3]]])\n",
    "print(a,a.shape)\n",
    "\n",
    "a.repeat_interleave(repeats=2,dim=0),torch.cat([a.unsqueeze(dim=1)]*2,dim=1).view(-1,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `permute`\n",
    "\n",
    "let's suppose there is a tensor of $[dim0, dim1, dim2, dim3]$, then we permute it to $[dim3, dim1, dim2, dim0]$\n",
    "\n",
    "- **consequence**: origin value at $[a, b, c, d]$ will be switched to $[d, b, c, a]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros([5,4,3,2]),\n",
    "# say a=2, b=3, c=1, d=1,\n",
    "a[2,3,1,1] = 1,\n",
    "print(\"origin 1 at [2,3,1,1]: {}\".format(a[2,3,1,1])),\n",
    "b = a.permute(3,1,2,0),\n",
    "print(\"permuted 1 at [3,1,2,0]: {}\".format(b[1,3,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `nonzero`\n",
    "finding non-zero indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [1, 1]])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros(2,2)\n",
    "a[1,0] = 1\n",
    "a[1,1] = 1\n",
    "a.nonzero()"
   ]
  },
  {
   "source": [
    "### `matmul`\n",
    "tensor multiplication\n",
    "\n",
    "- Docs about this function is concise, I want to give an example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [1, 0, 0]],\n",
       " \n",
       "         [[2, 3, 4],\n",
       "          [0, 1, 0]]]),\n",
       " torch.Size([2, 2, 3]),\n",
       " tensor([[[1, 0],\n",
       "          [0, 1],\n",
       "          [1, 1]],\n",
       " \n",
       "         [[1, 1],\n",
       "          [0, 0],\n",
       "          [0, 1]]]),\n",
       " torch.Size([2, 3, 2]),\n",
       " tensor([[1, 0],\n",
       "         [0, 1],\n",
       "         [1, 1]]),\n",
       " torch.Size([3, 2]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[6, 7],\n",
       "          [0, 1]]]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[2, 6],\n",
       "          [0, 0]]]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[1, 4],\n",
       "          [1, 1]]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[[1,2,3],[1,0,0]],[[2,3,4],[0,1,0]]])\n",
    "b = torch.tensor([[[1,0],[0,1],[1,1]],[[1,1],[0,0],[0,1]]])\n",
    "\n",
    "a,a.shape, b, b.shape, b[0], b[0].shape,torch.matmul(a,b[0]), torch.matmul(a,b), torch.matmul(a[0],b), a[0].shape"
   ]
  },
  {
   "source": [
    "### `argmax`\n",
    "find index of max value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[0.9193, 0.9062, 0.3764],\n",
       "          [0.2910, 0.3237, 0.0300]],\n",
       " \n",
       "         [[0.9931, 0.2293, 0.9009],\n",
       "          [0.5535, 0.4756, 0.2353]]]),\n",
       " tensor([[0, 1],\n",
       "         [0, 0]]),\n",
       " tensor([[0, 0, 0],\n",
       "         [0, 1, 0]]),\n",
       " tensor([[1, 0, 1],\n",
       "         [1, 1, 1]]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand((2,2,3))\n",
    "# when dim=-1, find max value index per row\n",
    "# when dim=1, find max value index per col\n",
    "# when dim=0, find max value of the same entry among batches\n",
    "a, a.argmax(dim=-1), a.argmax(dim=1), a.argmax(dim=0)"
   ]
  },
  {
   "source": [
    "### `sort`\n",
    "\n",
    "- sort value of tensor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[0.8392, 0.7046, 0.8891],\n",
       "          [0.7748, 0.7321, 0.1097]],\n",
       " \n",
       "         [[0.9433, 0.9492, 0.0342],\n",
       "          [0.4776, 0.9315, 0.7581]]]),\n",
       " tensor([[[0.8891, 0.8392, 0.7046],\n",
       "          [0.7748, 0.7321, 0.1097]],\n",
       " \n",
       "         [[0.9492, 0.9433, 0.0342],\n",
       "          [0.9315, 0.7581, 0.4776]]]),\n",
       " tensor([[[2, 0, 1],\n",
       "          [0, 1, 2]],\n",
       " \n",
       "         [[1, 0, 2],\n",
       "          [1, 2, 0]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand((2,2,3))\n",
    "b,c = a.sort(dim=-1, descending=True)\n",
    "a, b, c"
   ]
  },
  {
   "source": [
    "## torch.nn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `nn.ConvX`\n",
    "\n",
    "- calculate *signal_length* $L_{out}$ after convolution:\n",
    "\n",
    "    - consider a sequence of length $L_{in}$ of $C_{in}$ channels, then the output sequence is generated from $(d-1) * (k-1) - p$ to $L_{in} + p$, thus $L_{out}$ as the number of convolution calculations can be derived as $$L_{out} = \\lfloor\\frac{L_{in} - d * (k-1) - 1 + 2*p}{s} + 1\\rfloor$$where $d$ denotes *dilation rate*, $k$ denotes *kernel_size*, $p$ denotes *padding(on both sides)* and $s$ denotes *stride*\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `nn.LayerNorm`\n",
    "\n",
    "- *mean and variance* is calculated on each sample rather over the whole batch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `learning-to-rank`\n",
    "\n",
    "- say we got a vector for the relatedness between *query* and *doc*, then we feed the vector into a *MLP(i.e. Multi-Layer Perceptron)* to project the vector into a single value, which stands for the *score*. The above procedure is namely **Learning to Rank** because the weights of *MLP* can be learnt automatically."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `indice embedding`\n",
    "\n",
    "sometimes we have to create an embedding layer (*loop up layer*). \n",
    "\n",
    "The derivation from emebdding layer is straight forward: the last |n-1| dimension in embedding layer will be appended to the index tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 dimensional embedding:tensor([[[0.4890, 0.8069, 0.8093],\n         [0.6145, 0.3115, 0.6036]],\n\n        [[0.3977, 0.5009, 0.9692],\n         [0.8422, 0.7311, 0.7406]]]) of size torch.Size([2, 2, 3])\n\n2 dimensional embedding:tensor([[[[4.3572e-01, 3.7110e-01, 5.5503e-01],\n          [3.4236e-01, 3.0673e-01, 7.1331e-01],\n          [2.3374e-01, 3.6648e-01, 9.3444e-01],\n          [4.8977e-01, 9.6126e-01, 5.6057e-02],\n          [5.8815e-01, 6.7106e-01, 9.9311e-01]],\n\n         [[5.7527e-01, 2.8838e-01, 8.5722e-01],\n          [5.2984e-01, 8.5100e-02, 5.7482e-01],\n          [7.2258e-01, 2.0804e-01, 7.0520e-02],\n          [9.9510e-01, 8.3778e-01, 6.3597e-01],\n          [5.6489e-01, 3.9864e-01, 6.1766e-01]]],\n\n\n        [[[5.9626e-01, 9.5241e-02, 8.3267e-01],\n          [1.1131e-01, 3.0026e-01, 6.5316e-01],\n          [6.7256e-01, 4.0614e-01, 6.9878e-01],\n          [7.8866e-01, 7.1249e-01, 7.5015e-01],\n          [2.0895e-01, 5.7120e-01, 8.2893e-01]],\n\n         [[7.8303e-04, 1.8824e-01, 4.3864e-01],\n          [3.3937e-01, 3.7026e-01, 9.4996e-01],\n          [9.8147e-01, 7.1041e-01, 6.8880e-01],\n          [8.0600e-01, 2.4338e-01, 9.8605e-02],\n          [8.7597e-01, 7.4632e-02, 4.3825e-01]]]]) of size torch.Size([2, 2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embedding_layer = torch.rand((5,3))\n",
    "index_tensor = torch.tensor([[3,4],[0,1]]) # only tensor of dtype=torch.long works\n",
    "print(\"1 dimensional embedding:{} of size {}\\n\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))\n",
    "\n",
    "embedding_layer = torch.rand((5,5,3))\n",
    "print(\"2 dimensional embedding:{} of size {}\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))"
   ]
  },
  {
   "source": [
    "### `nn.CosineSimilarity`\n",
    "`PyTorch` provides convenient api for computing cosine similarity between two tensor, however it's confusing when dimension is more than one.\n",
    "\n",
    "- From my perspective, the `dim` parameter can be viewed as the dimension to *compress*, which means computing cosine similarity along `dim` is actually transforming the vector on this dimension to a single value.\n",
    "- As for calculating, we first slice the tensor of given `dim` and compute cosine similarity pair-wise\n",
    "- when `dim` is higher dimension:\n",
    "    - `dim` = $n$, $n>=2$: value at the same place across the given dimension will be packed into a vector\n",
    "    - `dim` = -1: value at the last dimension will be collected into a vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.7652, 0.9477],\n",
       "         [0.9658, 0.5803],\n",
       "         [0.6498, 0.9634]]),\n",
       " tensor([0.7652, 0.9477]),\n",
       " tensor([0.7652, 0.9658, 0.6498]),\n",
       " tensor([0.9477, 0.5803, 0.9634]))"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "\" example for cosine similarity along the last dimension \"\n",
    "cos = CosineSimilarity(dim=2)\n",
    "\n",
    "a = torch.rand((3,2,3))\n",
    "b = torch.rand((3,2,3))\n",
    "\n",
    "c = a[0]\n",
    "d = b[0]\n",
    "\n",
    "e = a[:,0,:].unsqueeze(dim=1)\n",
    "f = b[:,0,:].unsqueeze(dim=2)\n",
    "g = a[:,1,:].unsqueeze(dim=1)\n",
    "h = b[:,1,:].unsqueeze(dim=2)\n",
    "\n",
    "result_1 = torch.matmul(e,f) / torch.sqrt(torch.matmul(e,e.permute(0,2,1)) * torch.matmul(f.permute(0,2,1),f))\n",
    "result_2 = torch.matmul(g,h) / torch.sqrt(torch.matmul(g,g.permute(0,2,1)) * torch.matmul(h.permute(0,2,1),h))\n",
    "\n",
    "cos_2 = CosineSimilarity(dim=1)\n",
    "cos(a,b), cos_2(c,d), result_1.squeeze(), result_2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0., 0.]]),\n",
       " tensor([[0., 0.],\n",
       "         [0., 0.]]),\n",
       " tensor([[0.8044, 0.7442],\n",
       "         [0.1688, 0.2175]]),\n",
       " tensor([0., 0.]),\n",
       " tensor([0., 0.]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "cos = CosineSimilarity(dim=-1)\n",
    "a = torch.zeros((1,2))\n",
    "b = torch.zeros((2,2))\n",
    "c = torch.rand(2,2)\n",
    "a,b,c,cos(a,b),cos(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1., 2., 3.]]]),\n",
       " tensor([[[ 1.,  2.,  3.],\n",
       "          [ 2.,  3.,  4.]],\n",
       " \n",
       "         [[ 5.,  6.,  9.],\n",
       "          [-9., -2., -7.]]]),\n",
       " tensor([[ 1.0000,  0.9926],\n",
       "         [ 0.9868, -0.7850]]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\" broadcast in CosineSimilarity \"\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.nn import CosineSimilarity\n",
    "from utils.TestTensors import t_2_2_3\n",
    "\n",
    "cos = CosineSimilarity(dim=-1)\n",
    "a = torch.tensor([[[1,2,3.]]])\n",
    "a, t_2_2_3, cos(a,t_2_2_3)"
   ]
  },
  {
   "source": [
    "### `nn.LayerNorm`\n",
    "\n",
    "Layer Normalization is applied over the last given dimensions of the input tensor, i.e. `mean` and `variance` are calculated within the current input, rather than the whole batch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-0.5000,  0.5000,  0.0000],\n",
       "          [ 0.0000,  1.0000, -1.0000]],\n",
       " \n",
       "         [[ 1.0000,  2.0000,  3.0000],\n",
       "          [ 5.0000,  9.0000, 11.0000]]]),\n",
       " tensor([[[-0.7746,  0.7746,  0.0000],\n",
       "          [ 0.0000,  1.5492, -1.5492]],\n",
       " \n",
       "         [[-1.1352, -0.8627, -0.5903],\n",
       "          [-0.0454,  1.0444,  1.5893]]], grad_fn=<NativeLayerNormBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "LayerNorm = torch.nn.LayerNorm((2,3))\n",
    "a = torch.tensor([[[-0.5,0.5,0],[0,1,-1]],[[1,2,3],[5,9,11]]])\n",
    "a,LayerNorm(a)"
   ]
  },
  {
   "source": [
    "## torch.nn.functional"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `F.normalize()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]]],\n",
       " \n",
       " \n",
       "         [[[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]],\n",
       " \n",
       "          [[1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.],\n",
       "           [1., 1., 1., 1.]]]]),\n",
       " tensor([[[[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000]],\n",
       " \n",
       "          [[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000]]],\n",
       " \n",
       " \n",
       "         [[[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000]],\n",
       " \n",
       "          [[0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000],\n",
       "           [0.5000, 0.5000, 0.5000, 0.5000]]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "a = torch.ones((2,2,3,4))\n",
    "b = F.normalize(a, dim=-1)\n",
    "a,b"
   ]
  },
  {
   "source": [
    "### `F.one_hot`\n",
    "see document"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[0.7259, 0.4600, 0.1225],\n",
       "          [0.1762, 0.3771, 0.0185]],\n",
       " \n",
       "         [[0.3044, 0.0490, 0.4388],\n",
       "          [0.8985, 0.5789, 0.2526]]]),\n",
       " tensor([[0, 1],\n",
       "         [2, 0]]),\n",
       " tensor([[[1, 0, 0],\n",
       "          [0, 1, 0]],\n",
       " \n",
       "         [[0, 0, 1],\n",
       "          [1, 0, 0]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "a = torch.rand((2,2,3))\n",
    "b = a.argmax(dim=-1)\n",
    "c = F.one_hot(b,num_classes=a.shape[-1])\n",
    "a,b,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.autograd"
   ]
  },
  {
   "source": [
    "Only when the operation in the forward phrase is **not differentiable** while you want the gradient to be pass through that you should rewrite torch.autograd, where you can define your own backward algorithm to give an approximate gradient of the **indifferentiable** operation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### `detach` \n",
    "\n",
    "*Straight-through trick*\n",
    "\n",
    "- transform a tensor while keep its gradient unchanged"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[2.0000e-04, 4.0000e+01]], requires_grad=True),\n",
       " tensor([[ 0., 40.]], grad_fn=<AddBackward0>))"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[0.0002,40.]],requires_grad=True)\n",
    "b = torch.tensor([[0.,40.]]) - a.detach() + a\n",
    "a,b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}