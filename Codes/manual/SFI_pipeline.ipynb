{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import evaluate,train,prepare,my_collate\n",
    "from utils.MIND import MIND_news\n",
    "from models.SFI_FIM import SFIModel_pipeline1\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'scale':'large',\n",
    "    'mode':'train',\n",
    "    'name':'sfi-fim',\n",
    "    'batch_size':100,\n",
    "    'title_size':20,\n",
    "    'his_size':50,\n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'embedding_dim':300,\n",
    "    'filter_num':150,\n",
    "    'epochs':1,\n",
    "    'metrics':'group_auc,mean_mrr,ndcg@5,ndcg@10',\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'integration':'harmony',\n",
    "    'k':10,\n",
    "    'save_step':0,\n",
    "    'save_each_epoch':True,\n",
    "    'train_embedding':True\n",
    "}\n",
    "\n",
    "device = torch.device(hparams['device'])\n",
    "# torch.cuda.set_device(hparams['device'])\n",
    "\n",
    "path='/home/peitian_zhang/Data/MIND'\n",
    "news_file_train = path+'/MIND'+hparams['scale']+'_train/news.tsv'\n",
    "news_file_test = path+'/MIND'+hparams['scale']+'_dev/news.tsv'\n",
    "behavior_file_train = path+'/MIND'+hparams['scale']+'_train/behaviors.tsv'\n",
    "behavior_file_test = path+'/MIND'+hparams['scale']+'_dev/behaviors.tsv'\n",
    "mind_news = MIND_news(hparams, news_file_train)\n",
    "news_loader = torch.utils.data.DataLoader(mind_news,batch_size=hparams['batch_size'],pin_memory=True,num_workers=8,drop_last=False,collate_fn=my_collate)\n",
    "\n",
    "vocab = mind_news.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(news_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "record['candidate_title'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams['select'] = 'pipeline'\n",
    "sfiModel_pipeline1 = SFIModel_pipeline1(hparams, vocab=vocab, pipeline=True).to(device)\n",
    "\n",
    "sfiModel_pipeline1.load_state_dict(torch.load('/home/peitian_zhang/Codes/News-Recommendation/models/model_params/sfi-fim-pipeline_large_epoch1_[hs=50,topk=30].model'))\n",
    "sfiModel_pipeline1.cdd_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_num_dict = {\n",
    "    'small': 51282,\n",
    "    'large': 101527\n",
    "}\n",
    "news_num = 101527\n",
    "\n",
    "model = sfiModel_pipeline1\n",
    "news_reprs = torch.zeros((news_num + 1,model.filter_num))\n",
    "news_embeddings = torch.zeros((news_num + 1,model.signal_length,model.level,model.filter_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1016it [00:41, 24.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i,x in tqdm(enumerate(news_loader)):\n",
    "    embedding, repr = sfiModel_pipeline1(x)\n",
    "    for i in range(embedding.shape[0]):\n",
    "        news_reprs[x['news_id'][i]] = repr[i].to('cpu')\n",
    "        news_embeddings[x['news_id'][i]] = embedding[i].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(news_reprs, 'data/tensors/news_reprs_{}_{}.tensor'.format(hparams['scale'],hparams['mode']))\n",
    "torch.save(news_embeddings, 'data/tensors/news_embeddings_{}_{}.tensor'.format(hparams['scale'],hparams['mode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SFI_FIM import SFIModel_pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'scale':'large',\n",
    "    'mode':'train',\n",
    "    'name':'sfi-fim',\n",
    "    'batch_size':100,\n",
    "    'title_size':20,\n",
    "    'his_size':50,\n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'embedding_dim':300,\n",
    "    'filter_num':150,\n",
    "    'epochs':1,\n",
    "    'metrics':'group_auc,mean_mrr,ndcg@5,ndcg@10',\n",
    "    'device':'cuda:0',\n",
    "    'attrs': ['title'],\n",
    "    'integration':'harmony',\n",
    "    'k':10,\n",
    "    'save_step':0,\n",
    "    'save_each_epoch':True,\n",
    "    'train_embedding':True,\n",
    "    'news_id':True\n",
    "}\n",
    "device = torch.device(hparams['device'])\n",
    "vocab,loader_train,loader_test = prepare(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SFIModel_pipeline2(nn.Module):\n",
    "    def __init__(self,hparams,vocab):\n",
    "        super().__init__()\n",
    "        self.name = hparams['name']\n",
    "        self.metrics = hparams['metrics']\n",
    "\n",
    "        self.cdd_size = (hparams['npratio'] + 1) if hparams['npratio'] > 0 else 1\n",
    "        self.his_size =hparams['his_size']\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        \n",
    "        # concatenate category embedding and subcategory embedding\n",
    "        self.signal_length = hparams['title_size']# + 1 + 1\n",
    "        self.filter_num = hparams['filter_num']\n",
    "        self.k = hparams['k']\n",
    "        self.level = 3\n",
    "\n",
    "        self.device = hparams['device']\n",
    "\n",
    "        self.news_reprs = torch.load('data/tensors/news_reprs_{}_{}.tensor'.format(hparams['scale'],hparams['mode'])).to(self.device)\n",
    "        self.news_embeddings = torch.load('data/tensors/news_embeddings_{}_{}.tensor'.format(hparams['scale'],hparams['mode'])).to(self.device)\n",
    "\n",
    "        # elements in the slice along dim will sum up to 1 \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.learningToRank = nn.Linear(self.his_size,1)\n",
    "        self.SeqCNN3D = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=3,out_channels=32,kernel_size=[3,3,3],padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=[3,3,3],stride=[3,3,3]),\n",
    "            nn.Conv3d(in_channels=32,out_channels=16,kernel_size=[3,3,3],padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=[3,3,3],stride=[3,3,3])\n",
    "        )\n",
    "        self.learningToRank = nn.Linear(int((int((self.k - 3)/3 + 1) - 3)/3 + 1) * 2 * 2 * 16,1)\n",
    "    \n",
    "    def _scaled_dp_attention(self,query,key,value):\n",
    "        \"\"\" calculate scaled attended output of values\n",
    "        \n",
    "        Args:\n",
    "            query: tensor of [*, query_num, key_dim]\n",
    "            key: tensor of [batch_size, *, key_num, key_dim]\n",
    "            value: tensor of [batch_size, *, key_num, value_dim]\n",
    "        \n",
    "        Returns:\n",
    "            attn_output: tensor of [batch_size, *, query_num, value_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # make sure dimension matches\n",
    "        assert query.shape[-1] == key.shape[-1]\n",
    "        key = key.transpose(-2,-1)\n",
    "\n",
    "        attn_weights = torch.matmul(query,key)/torch.sqrt(torch.tensor([self.embedding_dim],dtype=torch.float,device=self.device))\n",
    "        attn_weights = self.softmax(attn_weights)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_weights,value)\n",
    "        return attn_output.squeeze(dim=-2)\n",
    "\n",
    "    def _fusion(self,cdd_news_reprs,his_news_reprs):\n",
    "        \"\"\" construct fusion tensor between candidate news repr and history news repr at each dilation level\n",
    "\n",
    "        Args:\n",
    "            cdd_news_reprs: tensor of [batch_size, cdd_size, signal_length, level, filter_num]\n",
    "            his_activated: tensor of [batch_size, cdd_size, k, signal_length, level, filter_num]\n",
    "\n",
    "        Returns:\n",
    "            fusion_tensor: tensor of [batch_size, *], where * is derived from MaxPooling with no padding\n",
    "        \"\"\"\n",
    "\n",
    "        # [batch_size, cdd_size, his_size, level, signal_length, signal_length]\n",
    "        cdd_news_reprs = cdd_news_reprs.transpose(-2,-3)\n",
    "        his_news_reprs = his_news_reprs.transpose(-2,-3)\n",
    "\n",
    "        fusion_tensor = torch.matmul(cdd_news_reprs.unsqueeze(dim=2),his_news_reprs.transpose(-2,-1)) / math.sqrt(self.filter_num)\n",
    "        # print(fusion_tensor.shape)\n",
    "        \n",
    "        # reshape the tensor in order to feed into 3D CNN pipeline\n",
    "        fusion_tensor = fusion_tensor.view(-1, self.k, self.level, self.signal_length, self.signal_length).transpose(1,2)\n",
    "\n",
    "        fusion_tensor = self.SeqCNN3D(fusion_tensor).view(self.batch_size,self.cdd_size,-1)\n",
    "        \n",
    "        return fusion_tensor\n",
    "\n",
    "    def _click_predictor(self,fusion_tensors):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            fusion_tensors: tensor of [batch_size, cdd_size, 320]\n",
    "        \n",
    "        Returns:\n",
    "            score: tensor of [batch_size, npratio+1], which is normalized click probabilty\n",
    "        \"\"\"\n",
    "        score = self.learningToRank(fusion_tensors).squeeze(dim=-1)\n",
    "        if self.cdd_size > 1:\n",
    "            score = nn.functional.log_softmax(score,dim=1)\n",
    "        else:\n",
    "            score = torch.sigmoid(score).squeeze(dim=-1)\n",
    "        return score\n",
    "\n",
    "    def forward(self,x):\n",
    "        if x['candidate_title'].shape[0] != self.batch_size:\n",
    "            self.batch_size = x['candidate_title'].shape[0]\n",
    "    \n",
    "        cdd_news_id = x['cdd_id'].long().to(self.device)\n",
    "        cdd_repr = self.news_reprs[cdd_news_id]\n",
    "        cdd_embedding = self.news_embeddings[cdd_news_id]\n",
    "\n",
    "        his_news_id = x['his_id'].long().to(self.device)\n",
    "        his_repr = self.news_reprs[his_news_id]\n",
    "        his_embedding = self.news_embeddings[his_news_id]\n",
    "\n",
    "        attn_weights = self.softmax(torch.bmm(cdd_repr, his_repr.transpose(-1,-2)))\n",
    "        _, attn_weights_sorted = attn_weights.detach().sort(dim=-1, descending=True)\n",
    "        attn_focus = F.one_hot(attn_weights_sorted[:,:,:self.k], num_classes=self.his_size).float()\n",
    "\n",
    "        # [bs, cs, k, sl, 3, fn]\n",
    "        his_activated = torch.matmul(attn_focus, his_embedding.view(self.batch_size, 1, self.his_size,-1)).view(self.batch_size, self.cdd_size, self.k, self.signal_length, self.level, self.filter_num)\n",
    "\n",
    "        fusion_tensors = self._fusion(cdd_news_embedding, his_activated)\n",
    "        \n",
    "        score = self._click_predictor(fusion_tensors)\n",
    "        return score\n",
    "\n",
    "sfiModel_pipeline2 = SFIModel_pipeline2(hparams,vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfiModel_pipeline2(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(sfiModel_pipeline2, hparams, loader_train, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}