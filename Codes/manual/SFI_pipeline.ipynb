{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitnnconda048fc75fe4ee43f1aa97608c8881ebba",
   "display_name": "Python 3.8.5 64-bit ('nn': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('../')\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from utils.utils import evaluate,train,prepare,my_collate\n",
    "from utils.MIND import MIND_news\n",
    "from models.SFI_FIM import SFIModel_pipeline1\n",
    "from torchtext.vocab import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'scale':'large',\n",
    "    'mode':'train',\n",
    "    'name':'sfi-fim',\n",
    "    'batch_size':100,\n",
    "    'title_size':20,\n",
    "    'his_size':50,\n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'embedding_dim':300,\n",
    "    'filter_num':150,\n",
    "    'epochs':1,\n",
    "    'metrics':'group_auc,mean_mrr,ndcg@5,ndcg@10',\n",
    "    'device':'cpu',\n",
    "    'attrs': ['title'],\n",
    "    'integration':'harmony',\n",
    "    'k':10,\n",
    "    'save_step':0,\n",
    "    'save_each_epoch':True,\n",
    "    'train_embedding':True\n",
    "}\n",
    "\n",
    "device = torch.device(hparams['device'])\n",
    "# torch.cuda.set_device(hparams['device'])\n",
    "\n",
    "path='/home/peitian_zhang/Data/MIND'\n",
    "news_file_train = path+'/MIND'+hparams['scale']+'_train/news.tsv'\n",
    "news_file_test = path+'/MIND'+hparams['scale']+'_dev/news.tsv'\n",
    "behavior_file_train = path+'/MIND'+hparams['scale']+'_train/behaviors.tsv'\n",
    "behavior_file_test = path+'/MIND'+hparams['scale']+'_dev/behaviors.tsv'\n",
    "mind_news = MIND_news(hparams, news_file_train)\n",
    "news_loader = torch.utils.data.DataLoader(mind_news,batch_size=hparams['batch_size'],pin_memory=True,num_workers=8,drop_last=False,collate_fn=my_collate)\n",
    "\n",
    "vocab = mind_news.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(news_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "record['candidate_title'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams['select'] = 'pipeline'\n",
    "sfiModel_pipeline1 = SFIModel_pipeline1(hparams, vocab=vocab, pipeline=True).to(device)\n",
    "\n",
    "sfiModel_pipeline1.load_state_dict(torch.load('/home/peitian_zhang/Codes/News-Recommendation/models/model_params/sfi-fim-pipeline_large_epoch1_[hs=50,topk=30].model'))\n",
    "sfiModel_pipeline1.cdd_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_num_dict = {\n",
    "    'small': 51282,\n",
    "    'large': 101527\n",
    "}\n",
    "news_num = 101527\n",
    "\n",
    "model = sfiModel_pipeline1\n",
    "news_reprs = torch.zeros((news_num + 1,model.filter_num))\n",
    "news_embeddings = torch.zeros((news_num + 1,model.signal_length,model.level,model.filter_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1016it [00:41, 24.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i,x in tqdm(enumerate(news_loader)):\n",
    "    embedding, repr = sfiModel_pipeline1(x)\n",
    "    for i in range(embedding.shape[0]):\n",
    "        news_reprs[x['news_id'][i]] = repr[i].to('cpu')\n",
    "        news_embeddings[x['news_id'][i]] = embedding[i].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(news_reprs, 'data/tensors/news_reprs_{}_{}.tensor'.format(hparams['scale'],hparams['mode']))\n",
    "torch.save(news_embeddings, 'data/tensors/news_embeddings_{}_{}.tensor'.format(hparams['scale'],hparams['mode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SFI_FIM import SFIModel_pipeline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'scale':'large',\n",
    "    'mode':'train',\n",
    "    'name':'sfi-fim',\n",
    "    'batch_size':100,\n",
    "    'title_size':20,\n",
    "    'his_size':50,\n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'embedding_dim':300,\n",
    "    'filter_num':150,\n",
    "    'epochs':1,\n",
    "    'metrics':'group_auc,mean_mrr,ndcg@5,ndcg@10',\n",
    "    'device':'cuda:0',\n",
    "    'attrs': ['title'],\n",
    "    'integration':'harmony',\n",
    "    'k':10,\n",
    "    'save_step':0,\n",
    "    'save_each_epoch':True,\n",
    "    'train_embedding':True,\n",
    "    'news_id':True\n",
    "}\n",
    "device = torch.device(hparams['device'])\n",
    "vocab,loader_train,loader_test = prepare(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SFIModel_pipeline2(nn.Module):\n",
    "    def __init__(self,hparams,vocab):\n",
    "        super().__init__()\n",
    "        self.name = hparams['name']\n",
    "        self.metrics = hparams['metrics']\n",
    "\n",
    "        self.cdd_size = (hparams['npratio'] + 1) if hparams['npratio'] > 0 else 1\n",
    "        self.his_size =hparams['his_size']\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        \n",
    "        # concatenate category embedding and subcategory embedding\n",
    "        self.signal_length = hparams['title_size']# + 1 + 1\n",
    "        self.filter_num = hparams['filter_num']\n",
    "        self.k = hparams['k']\n",
    "        self.level = 3\n",
    "\n",
    "        self.device = hparams['device']\n",
    "\n",
    "        self.news_reprs = torch.load('data/tensors/news_reprs_{}_{}.tensor'.format(hparams['scale'],hparams['mode'])).to(self.device)\n",
    "        self.news_embeddings = torch.load('data/tensors/news_embeddings_{}_{}.tensor'.format(hparams['scale'],hparams['mode'])).to(self.device)\n",
    "\n",
    "        # elements in the slice along dim will sum up to 1 \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.learningToRank = nn.Linear(self.his_size,1)\n",
    "        self.SeqCNN3D = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=3,out_channels=32,kernel_size=[3,3,3],padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=[3,3,3],stride=[3,3,3]),\n",
    "            nn.Conv3d(in_channels=32,out_channels=16,kernel_size=[3,3,3],padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=[3,3,3],stride=[3,3,3])\n",
    "        )\n",
    "        self.learningToRank = nn.Linear(int((int((self.k - 3)/3 + 1) - 3)/3 + 1) * 2 * 2 * 16,1)\n",
    "    \n",
    "    def _scaled_dp_attention(self,query,key,value):\n",
    "        \"\"\" calculate scaled attended output of values\n",
    "        \n",
    "        Args:\n",
    "            query: tensor of [*, query_num, key_dim]\n",
    "            key: tensor of [batch_size, *, key_num, key_dim]\n",
    "            value: tensor of [batch_size, *, key_num, value_dim]\n",
    "        \n",
    "        Returns:\n",
    "            attn_output: tensor of [batch_size, *, query_num, value_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        # make sure dimension matches\n",
    "        assert query.shape[-1] == key.shape[-1]\n",
    "        key = key.transpose(-2,-1)\n",
    "\n",
    "        attn_weights = torch.matmul(query,key)/torch.sqrt(torch.tensor([self.embedding_dim],dtype=torch.float,device=self.device))\n",
    "        attn_weights = self.softmax(attn_weights)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_weights,value)\n",
    "        return attn_output.squeeze(dim=-2)\n",
    "\n",
    "    def _fusion(self,cdd_news_reprs,his_news_reprs):\n",
    "        \"\"\" construct fusion tensor between candidate news repr and history news repr at each dilation level\n",
    "\n",
    "        Args:\n",
    "            cdd_news_reprs: tensor of [batch_size, cdd_size, signal_length, level, filter_num]\n",
    "            his_activated: tensor of [batch_size, cdd_size, k, signal_length, level, filter_num]\n",
    "\n",
    "        Returns:\n",
    "            fusion_tensor: tensor of [batch_size, *], where * is derived from MaxPooling with no padding\n",
    "        \"\"\"\n",
    "\n",
    "        # [batch_size, cdd_size, his_size, level, signal_length, signal_length]\n",
    "        cdd_news_reprs = cdd_news_reprs.transpose(-2,-3)\n",
    "        his_news_reprs = his_news_reprs.transpose(-2,-3)\n",
    "\n",
    "        fusion_tensor = torch.matmul(cdd_news_reprs.unsqueeze(dim=2),his_news_reprs.transpose(-2,-1)) / math.sqrt(self.filter_num)\n",
    "        # print(fusion_tensor.shape)\n",
    "        \n",
    "        # reshape the tensor in order to feed into 3D CNN pipeline\n",
    "        fusion_tensor = fusion_tensor.view(-1, self.k, self.level, self.signal_length, self.signal_length).transpose(1,2)\n",
    "\n",
    "        fusion_tensor = self.SeqCNN3D(fusion_tensor).view(self.batch_size,self.cdd_size,-1)\n",
    "        \n",
    "        return fusion_tensor\n",
    "\n",
    "    def _click_predictor(self,fusion_tensors):\n",
    "        \"\"\" calculate batch of click probabolity\n",
    "\n",
    "        Args:\n",
    "            fusion_tensors: tensor of [batch_size, cdd_size, 320]\n",
    "        \n",
    "        Returns:\n",
    "            score: tensor of [batch_size, npratio+1], which is normalized click probabilty\n",
    "        \"\"\"\n",
    "        score = self.learningToRank(fusion_tensors).squeeze(dim=-1)\n",
    "        if self.cdd_size > 1:\n",
    "            score = nn.functional.log_softmax(score,dim=1)\n",
    "        else:\n",
    "            score = torch.sigmoid(score).squeeze(dim=-1)\n",
    "        return score\n",
    "\n",
    "    def forward(self,x):\n",
    "        if x['candidate_title'].shape[0] != self.batch_size:\n",
    "            self.batch_size = x['candidate_title'].shape[0]\n",
    "    \n",
    "        cdd_news_id = x['cdd_id'].long().to(self.device)\n",
    "        cdd_repr = self.news_reprs[cdd_news_id]\n",
    "        cdd_embedding = self.news_embeddings[cdd_news_id]\n",
    "\n",
    "        his_news_id = x['his_id'].long().to(self.device)\n",
    "        his_repr = self.news_reprs[his_news_id]\n",
    "        his_embedding = self.news_embeddings[his_news_id]\n",
    "\n",
    "        attn_weights = self.softmax(torch.bmm(cdd_repr, his_repr.transpose(-1,-2)))\n",
    "        _, attn_weights_sorted = attn_weights.detach().sort(dim=-1, descending=True)\n",
    "        attn_focus = F.one_hot(attn_weights_sorted[:,:,:self.k], num_classes=self.his_size).float()\n",
    "\n",
    "        # [bs, cs, k, sl, 3, fn]\n",
    "        his_activated = torch.matmul(attn_focus, his_embedding.view(self.batch_size, 1, self.his_size,-1)).view(self.batch_size, self.cdd_size, self.k, self.signal_length, self.level, self.filter_num)\n",
    "\n",
    "        fusion_tensors = self._fusion(cdd_embedding, his_activated)\n",
    "        \n",
    "        score = self._click_predictor(fusion_tensors)\n",
    "        return score\n",
    "\n",
    "sfiModel_pipeline2 = SFIModel_pipeline2(hparams,vocab).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = next(iter(loader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-1.5548, -1.5655, -1.6545, -1.6259, -1.6509],\n",
       "        [-1.5772, -1.7154, -1.5231, -1.6466, -1.5954],\n",
       "        [-1.6432, -1.5850, -1.5375, -1.6722, -1.6148],\n",
       "        [-1.5898, -1.6590, -1.6568, -1.5039, -1.6466],\n",
       "        [-1.6129, -1.6411, -1.6591, -1.5614, -1.5763],\n",
       "        [-1.7899, -1.8136, -1.7710, -1.3867, -1.3867],\n",
       "        [-1.5782, -1.5762, -1.6296, -1.7041, -1.5656],\n",
       "        [-1.5427, -1.5558, -1.5720, -1.7073, -1.6810],\n",
       "        [-1.5488, -1.5780, -1.6173, -1.6390, -1.6686],\n",
       "        [-1.5846, -1.6976, -1.5588, -1.6253, -1.5866],\n",
       "        [-1.5742, -1.5649, -1.5686, -1.7373, -1.6125],\n",
       "        [-1.8695, -1.9126, -1.4580, -1.4580, -1.4580],\n",
       "        [-1.6036, -1.6276, -1.5974, -1.6340, -1.5855],\n",
       "        [-1.6335, -1.6748, -1.6027, -1.5524, -1.5880],\n",
       "        [-1.6114, -1.6235, -1.6264, -1.5760, -1.6107],\n",
       "        [-1.5237, -1.6428, -1.6186, -1.6075, -1.6602],\n",
       "        [-1.6724, -1.6080, -1.7124, -1.4577, -1.6159],\n",
       "        [-1.6445, -1.5939, -1.5843, -1.6482, -1.5785],\n",
       "        [-1.5872, -1.6504, -1.6025, -1.5537, -1.6571],\n",
       "        [-1.5720, -1.5964, -1.6708, -1.6229, -1.5880],\n",
       "        [-1.5879, -1.6845, -1.6637, -1.5389, -1.5796],\n",
       "        [-1.6106, -1.7490, -1.5687, -1.5314, -1.6008],\n",
       "        [-1.6863, -1.6167, -1.5576, -1.5781, -1.6133],\n",
       "        [-1.6277, -1.6308, -1.6212, -1.5689, -1.5999],\n",
       "        [-1.6018, -1.6399, -1.5709, -1.6413, -1.5952],\n",
       "        [-1.5812, -1.6109, -1.6350, -1.6084, -1.6124],\n",
       "        [-1.5721, -1.5947, -1.6460, -1.5341, -1.7096],\n",
       "        [-1.5451, -1.5953, -1.6903, -1.6472, -1.5759],\n",
       "        [-1.5623, -1.6241, -1.6785, -1.5458, -1.6426],\n",
       "        [-1.6143, -1.5997, -1.7200, -1.5391, -1.5830],\n",
       "        [-1.5531, -1.6813, -1.5328, -1.6622, -1.6265],\n",
       "        [-1.6082, -1.6097, -1.6126, -1.5981, -1.6187],\n",
       "        [-1.7944, -1.8311, -1.8020, -1.3693, -1.3693],\n",
       "        [-1.9621, -1.8758, -1.4465, -1.4465, -1.4465],\n",
       "        [-1.6290, -1.6517, -1.5973, -1.5530, -1.6189],\n",
       "        [-1.5826, -1.6298, -1.6325, -1.5876, -1.6158],\n",
       "        [-1.6320, -1.6626, -1.5991, -1.5829, -1.5732],\n",
       "        [-1.5879, -1.5979, -1.6397, -1.5534, -1.6725],\n",
       "        [-1.6005, -1.5771, -1.7412, -1.5892, -1.5502],\n",
       "        [-1.5797, -1.6544, -1.6996, -1.5574, -1.5639],\n",
       "        [-1.6504, -1.6597, -1.5751, -1.5712, -1.5943],\n",
       "        [-1.6879, -1.8543, -1.7068, -1.6793, -1.2359],\n",
       "        [-1.6330, -1.5796, -1.6201, -1.6380, -1.5781],\n",
       "        [-1.5924, -1.5934, -1.5130, -1.7036, -1.6551],\n",
       "        [-1.5562, -1.7209, -1.5629, -1.5941, -1.6218],\n",
       "        [-1.6638, -1.5954, -1.6023, -1.6140, -1.5739],\n",
       "        [-1.6499, -1.5873, -1.6619, -1.5560, -1.5960],\n",
       "        [-1.5805, -1.6855, -1.5165, -1.6228, -1.6505],\n",
       "        [-1.5989, -1.6619, -1.5933, -1.5269, -1.6732],\n",
       "        [-1.7189, -1.6293, -1.5117, -1.5789, -1.6199],\n",
       "        [-1.5662, -1.5336, -1.6131, -1.7287, -1.6164],\n",
       "        [-1.5748, -1.6612, -1.6137, -1.6197, -1.5803],\n",
       "        [-1.6398, -1.5961, -1.5475, -1.6189, -1.6481],\n",
       "        [-1.5808, -1.6037, -1.6895, -1.5291, -1.6519],\n",
       "        [-1.6163, -1.6347, -1.5951, -1.6041, -1.5975],\n",
       "        [-1.5880, -1.5040, -1.6341, -1.6343, -1.6971],\n",
       "        [-1.5630, -1.6066, -1.6369, -1.6262, -1.6160],\n",
       "        [-1.6094, -1.6094, -1.6094, -1.6094, -1.6094],\n",
       "        [-1.7233, -1.7946, -1.7192, -1.6928, -1.2306],\n",
       "        [-1.6007, -1.5978, -1.7018, -1.6124, -1.5411],\n",
       "        [-1.6529, -1.5710, -1.5786, -1.6485, -1.5992],\n",
       "        [-1.5756, -1.5555, -1.6662, -1.6687, -1.5868],\n",
       "        [-1.5212, -1.6123, -1.6388, -1.6511, -1.6293],\n",
       "        [-1.5434, -1.6554, -1.6990, -1.5486, -1.6098],\n",
       "        [-1.6068, -1.5800, -1.5913, -1.6264, -1.6441],\n",
       "        [-1.6188, -1.6267, -1.6535, -1.5683, -1.5823],\n",
       "        [-1.6166, -1.6296, -1.5356, -1.6103, -1.6593],\n",
       "        [-1.5242, -1.6616, -1.6350, -1.5724, -1.6614],\n",
       "        [-1.6554, -1.5375, -1.6481, -1.5585, -1.6543],\n",
       "        [-1.9175, -1.8953, -1.4514, -1.4514, -1.4514],\n",
       "        [-1.6194, -1.5304, -1.6109, -1.6207, -1.6709],\n",
       "        [-1.6621, -1.5922, -1.6162, -1.5730, -1.6059],\n",
       "        [-1.8924, -2.0304, -1.4299, -1.4299, -1.4299],\n",
       "        [-1.6502, -1.5758, -1.5941, -1.5967, -1.6322],\n",
       "        [-1.5492, -1.6426, -1.6638, -1.6041, -1.5914],\n",
       "        [-1.5402, -1.6099, -1.6552, -1.6167, -1.6289],\n",
       "        [-1.5611, -1.6748, -1.6272, -1.5689, -1.6195],\n",
       "        [-1.6555, -1.5875, -1.5649, -1.6231, -1.6186],\n",
       "        [-1.7914, -1.8327, -1.4942, -1.4942, -1.4942],\n",
       "        [-1.6093, -1.5821, -1.6763, -1.6169, -1.5661],\n",
       "        [-1.6043, -1.6755, -1.5496, -1.6531, -1.5704],\n",
       "        [-1.6448, -1.5972, -1.6104, -1.5654, -1.6314],\n",
       "        [-1.6164, -1.5841, -1.6232, -1.6161, -1.6078],\n",
       "        [-1.6035, -1.6127, -1.5863, -1.6282, -1.6170],\n",
       "        [-1.6300, -1.6139, -1.5806, -1.6132, -1.6101],\n",
       "        [-1.6569, -1.6103, -1.5773, -1.5777, -1.6274],\n",
       "        [-1.6313, -1.5850, -1.6397, -1.6070, -1.5854],\n",
       "        [-1.6284, -1.5867, -1.6086, -1.6414, -1.5834],\n",
       "        [-1.5871, -1.6222, -1.6114, -1.6051, -1.6218],\n",
       "        [-1.6644, -1.5246, -1.6405, -1.6128, -1.6107],\n",
       "        [-1.6197, -1.6269, -1.5616, -1.6256, -1.6149],\n",
       "        [-1.7412, -1.7393, -1.6745, -1.6199, -1.3328],\n",
       "        [-1.6620, -1.5779, -1.6158, -1.5883, -1.6053],\n",
       "        [-1.6287, -1.7023, -1.5567, -1.5340, -1.6345],\n",
       "        [-1.5451, -1.6676, -1.6025, -1.6052, -1.6309],\n",
       "        [-1.6484, -1.6753, -1.5728, -1.5667, -1.5886],\n",
       "        [-1.5871, -1.5481, -1.6530, -1.5814, -1.6838],\n",
       "        [-1.6640, -1.6990, -1.5033, -1.5888, -1.6036],\n",
       "        [-1.7149, -1.6120, -1.5416, -1.4894, -1.7094],\n",
       "        [-1.5970, -1.6795, -1.5772, -1.6158, -1.5810]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "sfiModel_pipeline2(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training...\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.40 GiB (GPU 0; 11.75 GiB total capacity; 8.33 GiB already allocated; 1.73 GiB free; 8.93 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-53f3de945cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfiModel_pipeline2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Codes/News-Recommendation/utils/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, hparams, loader_train, loader_dev, loader_validate, tb, interval)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_each_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_each_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;31m# if save:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Codes/News-Recommendation/utils/utils.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(model, dataloader, optimizer, loss_func, hparams, writer, interval, save_step, save_each_epoch)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.40 GiB (GPU 0; 11.75 GiB total capacity; 8.33 GiB already allocated; 1.73 GiB free; 8.93 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "train(sfiModel_pipeline2, hparams, loader_train, loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}